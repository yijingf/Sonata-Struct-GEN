{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc048f1-bb54-4cb6-8489-cb8b2691db34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import mir_eval\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from utils.event import expand_score\n",
    "from utils.align import get_t_bar, get_t_fin\n",
    "from utils.common import get_file_list, load_event\n",
    "from utils.constants import DATA_DIR\n",
    "\n",
    "event_dir = os.path.join(DATA_DIR, \"event\")\n",
    "midi_dir = os.path.join(DATA_DIR, \"midi\")\n",
    "true_dir = os.path.join(DATA_DIR, \"struct_annotated\")\n",
    "pred_dir = os.path.join(DATA_DIR, \"struct_mark\")\n",
    "pred_theme_dir = os.path.join(DATA_DIR, \"struct_mark_theme\")\n",
    "triplet_bound_dir = os.path.join(DATA_DIR, \"boundary_predictions\")\n",
    "\n",
    "def get_t_bounds(struct):\n",
    "    sect_bounds = []\n",
    "    theme_bounds = []\n",
    "    for sect in struct.values():\n",
    "        sect_bounds.append(sect[-1]['end t'])\n",
    "        for theme in sect:\n",
    "            theme_bounds.append(theme['end t'])\n",
    "    return sect_bounds, theme_bounds\n",
    "\n",
    "def get_ts_cpt(composer, basename):\n",
    "\n",
    "    event_file = os.path.join(event_dir, composer, basename)\n",
    "    score_event, mark = load_event(event_file)\n",
    "    event, _ = expand_score(score_event, mark)\n",
    "\n",
    "    map_file = os.path.join(midi_dir, composer, basename)\n",
    "    with open(map_file) as f:\n",
    "        ts_cpt = json.load(f)[\"cpt\"]\n",
    "    t_fin = get_t_fin(max(event), ts_cpt)\n",
    "    ts_cpt.append({\"measure\": max(event) + 1, 't': float(t_fin),\n",
    "                   \"tempo\": ts_cpt[-1][\"tempo\"],\n",
    "                   \"time_signature\": ts_cpt[-1][\"time_signature\"]})\n",
    "    return ts_cpt\n",
    "\n",
    "def bound_to_interval(bounds):\n",
    "    bounds = [0] + bounds\n",
    "    return np.array([bounds[:-1], bounds[1:]]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7bb34d99-1a10-4375-95a2-f621cd65d938",
   "metadata": {},
   "outputs": [],
   "source": [
    "struct_file_list = get_file_list(true_dir)\n",
    "\n",
    "sect_p5_res, sect_3_res, sect_m_res = [], [], []\n",
    "theme_p5_res, theme_3_res, theme_m_res = [], [], []\n",
    "phrase_p5_res, phrase_3_res, phrase_m_res = [], [], []\n",
    "\n",
    "# Baseline\n",
    "b_sect_p5_res, b_sect_3_res, b_sect_m_res = [], [], []\n",
    "b_theme_p5_res, b_theme_3_res, b_theme_m_res = [], [], []\n",
    "b_phrase_p5_res, b_phrase_3_res, b_phrase_m_res = [], [], []\n",
    "\n",
    "for struct_file in struct_file_list:\n",
    "    \n",
    "    composer, basename = struct_file.split(\".json\")[0].split(\"/\")[-2:]\n",
    "    \n",
    "    ts_cpt = get_ts_cpt(composer, f\"{basename}.json\")\n",
    "    \n",
    "    max_t_bar = max([get_t_bar(**i) for i in ts_cpt])\n",
    "    \n",
    "    with open(struct_file) as f:\n",
    "        struct = json.load(f)['struct']\n",
    "    \n",
    "    sect_bounds, theme_bounds = get_t_bounds(struct)\n",
    "     \n",
    "    pred_struct_file = os.path.join(pred_dir, f\"{composer}-{basename}.json\")\n",
    "    with open(pred_struct_file) as f:\n",
    "        pred_struct = json.load(f)\n",
    "    pred_sect_bounds, pred_phrase_bounds = get_t_bounds(pred_struct)\n",
    "\n",
    "    pred_theme_file = os.path.join(pred_theme_dir, f\"{composer}-{basename}.json\")\n",
    "    with open(pred_theme_file) as f:\n",
    "        pred_theme = json.load(f)\n",
    "    _, pred_theme_bounds = get_t_bounds(pred_theme)\n",
    "\n",
    "    sect_intervals = bound_to_interval(sect_bounds)\n",
    "    pred_sect_intervals = bound_to_interval(pred_sect_bounds)\n",
    "    sect_p5_res += [mir_eval.segment.detection(sect_intervals, pred_sect_intervals, window=.5, )]\n",
    "    sect_3_res += [mir_eval.segment.detection(sect_intervals, pred_sect_intervals, window=3, )]\n",
    "    sect_m_res += [mir_eval.segment.detection(sect_intervals, pred_sect_intervals, window=max_t_bar, )]\n",
    "\n",
    "    theme_intervals = bound_to_interval(theme_bounds)\n",
    "    pred_theme_intervals = bound_to_interval(pred_theme_bounds)\n",
    "    theme_p5_res += [mir_eval.segment.detection(theme_intervals, pred_theme_intervals, window=.5, )]\n",
    "    theme_3_res += [mir_eval.segment.detection(theme_intervals, pred_theme_intervals, window=3, )]\n",
    "    theme_m_res += [mir_eval.segment.detection(theme_intervals, pred_theme_intervals, window=max_t_bar, )]\n",
    "\n",
    "    pred_phrase_intervals = bound_to_interval(pred_phrase_bounds)\n",
    "    phrase_p5_res += [mir_eval.segment.detection(theme_intervals, pred_phrase_intervals, window=.5, )]\n",
    "    phrase_3_res += [mir_eval.segment.detection(theme_intervals, pred_phrase_intervals, window=3, )]\n",
    "    phrase_m_res += [mir_eval.segment.detection(theme_intervals, pred_phrase_intervals, window=max_t_bar, )]\n",
    "\n",
    "    # Baseline\n",
    "    pred_bound_file = os.path.join(triplet_bound_dir, f\"{composer}-{basename}.pkl\")\n",
    "    with open(pred_bound_file, \"rb\") as f:\n",
    "        pred_bounds = pickle.load(f)\n",
    "\n",
    "    n_sect_level = 3\n",
    "    sect_intervals = pred_bounds[n_sect_level][0]\n",
    "    pred_sect_intervals = bound_to_interval(pred_sect_bounds)\n",
    "    b_sect_p5_res += [mir_eval.segment.detection(sect_intervals, pred_sect_intervals, window=.5, )]\n",
    "    b_sect_3_res += [mir_eval.segment.detection(sect_intervals, pred_sect_intervals, window=3, )]\n",
    "    b_sect_m_res += [mir_eval.segment.detection(sect_intervals, pred_sect_intervals, window=max_t_bar, )]\n",
    "\n",
    "    n_theme_level = 6\n",
    "    theme_intervals = pred_bounds[n_theme_level][0]\n",
    "    pred_theme_intervals = bound_to_interval(pred_theme_bounds)\n",
    "    b_theme_p5_res += [mir_eval.segment.detection(theme_intervals, pred_theme_intervals, window=.5, )]\n",
    "    b_theme_3_res += [mir_eval.segment.detection(theme_intervals, pred_theme_intervals, window=3, )]\n",
    "    b_theme_m_res += [mir_eval.segment.detection(theme_intervals, pred_theme_intervals, window=max_t_bar, )]\n",
    "\n",
    "    n_phrase_level = -1\n",
    "    pred_phrase_intervals = pred_bounds[n_phrase_level][0]\n",
    "    b_phrase_p5_res += [mir_eval.segment.detection(theme_intervals, pred_phrase_intervals, window=.5, )]\n",
    "    b_phrase_3_res += [mir_eval.segment.detection(theme_intervals, pred_phrase_intervals, window=3, )]\n",
    "    b_phrase_m_res += [mir_eval.segment.detection(theme_intervals, pred_phrase_intervals, window=max_t_bar, )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82a3f007-40e7-4a40-99fc-b589b7768871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Section Boundary\n",
      "Method 1                                                     Baseline\n",
      "Window       Precision    Recall       F1                    Precision    Recall       F1\n",
      ".5           0.7951       0.7928       0.7919                0.5333       0.1569       0.2385      \n",
      "3            0.9083       0.9043       0.9041                0.8585       0.2525       0.3836      \n",
      "measure      0.8653       0.8622       0.8616                0.7589       0.2219       0.3375      \n",
      "\n",
      "Thematic Material Boundary\n",
      "Method 1                                                     Baseline\n",
      "Window       Precision    Recall       F1                    Window      \n",
      ".5           0.3860       0.4701       0.4135                0.8094       0.6296       0.6925      \n",
      "3            0.5987       0.7602       0.6559                0.9632       0.7285       0.8070      \n",
      "measure      0.5268       0.6549       0.5713                0.9301       0.7013       0.7776      \n",
      "\n",
      "Phrase-Level Material Boundary\n",
      "Method 1                                                     Baseline\n",
      "Window       Precision    Recall       F1                    Window      \n",
      ".5           0.3483       0.4915       0.3889                0.3191       0.5190       0.3917      \n",
      "3            0.5332       0.8094       0.6168                0.5715       0.9328       0.7025      \n",
      "measure      0.4628       0.6692       0.5241                0.5050       0.8227       0.6204      \n"
     ]
    }
   ],
   "source": [
    "# precision, recall, f1\n",
    "avg_sect_p5 = np.mean(np.array(sect_p5_res), axis=0)\n",
    "avg_sect_3 = np.mean(np.array(sect_3_res), axis=0)\n",
    "avg_sect_m = np.mean(np.array(sect_m_res), axis=0)\n",
    "\n",
    "avg_theme_p5 = np.mean(np.array(theme_p5_res), axis=0)\n",
    "avg_theme_3 = np.mean(np.array(theme_3_res), axis=0)\n",
    "avg_theme_m = np.mean(np.array(theme_m_res), axis=0)\n",
    "\n",
    "avg_phrase_p5 = np.mean(np.array(phrase_p5_res), axis=0)\n",
    "avg_phrase_3 = np.mean(np.array(phrase_3_res), axis=0)\n",
    "avg_phrase_m = np.mean(np.array(phrase_m_res), axis=0)\n",
    "\n",
    "# Baseline\n",
    "avg_b_sect_p5 = np.mean(np.array(b_sect_p5_res), axis=0)\n",
    "avg_b_sect_3 = np.mean(np.array(b_sect_3_res), axis=0)\n",
    "avg_b_sect_m = np.mean(np.array(b_sect_m_res), axis=0)\n",
    "\n",
    "avg_b_theme_p5 = np.mean(np.array(b_theme_p5_res), axis=0)\n",
    "avg_b_theme_3 = np.mean(np.array(b_theme_3_res), axis=0)\n",
    "avg_b_theme_m = np.mean(np.array(b_theme_m_res), axis=0)\n",
    "\n",
    "avg_b_phrase_p5 = np.mean(np.array(b_phrase_p5_res), axis=0)\n",
    "avg_b_phrase_3 = np.mean(np.array(b_phrase_3_res), axis=0)\n",
    "avg_b_phrase_m = np.mean(np.array(b_phrase_m_res), axis=0)\n",
    "\n",
    "print('Section Boundary')\n",
    "print(f\"{'Method 1':<60} {'Baseline'}\")\n",
    "print(f\"{'Window':<12} {'Precision':<12} {'Recall':<12} {'F1':<21} {'Precision':<12} {'Recall':<12} {'F1'}\")\n",
    "print(f\"{'.5':<12} {avg_sect_p5[0]:<12.4f} {avg_sect_p5[1]:<12.4f} {avg_sect_p5[2]:<21.4f} {avg_b_sect_p5[0]:<12.4f} {avg_b_sect_p5[1]:<12.4f} {avg_b_sect_p5[2]:<12.4f}\")\n",
    "print(f\"{'3':<12} {avg_sect_3[0]:<12.4f} {avg_sect_3[1]:<12.4f} {avg_sect_3[2]:<21.4f} {avg_b_sect_3[0]:<12.4f} {avg_b_sect_3[1]:<12.4f} {avg_b_sect_3[2]:<12.4f}\")\n",
    "print(f\"{'measure':<12} {avg_sect_m[0]:<12.4f} {avg_sect_m[1]:<12.4f} {avg_sect_m[2]:<21.4f} {avg_b_sect_m[0]:<12.4f} {avg_b_sect_m[1]:<12.4f} {avg_b_sect_m[2]:<12.4f}\")\n",
    "print()\n",
    "\n",
    "print('Thematic Material Boundary')\n",
    "print(f\"{'Method 1':<60} {'Baseline'}\")\n",
    "print(f\"{'Window':<12} {'Precision':<12} {'Recall':<12} {'F1':<21} {'Window':<12}\")\n",
    "print(f\"{'.5':<12} {avg_theme_p5[0]:<12.4f} {avg_theme_p5[1]:<12.4f} {avg_theme_p5[2]:<21.4f} {avg_b_theme_p5 [0]:<12.4f} {avg_b_theme_p5 [1]:<12.4f} {avg_b_theme_p5 [2]:<12.4f}\")\n",
    "print(f\"{'3':<12} {avg_theme_3[0]:<12.4f} {avg_theme_3[1]:<12.4f} {avg_theme_3[2]:<21.4f} {avg_b_theme_3[0]:<12.4f} {avg_b_theme_3[1]:<12.4f} {avg_b_theme_3[2]:<12.4f}\")\n",
    "print(f\"{'measure':<12} {avg_theme_m[0]:<12.4f} {avg_theme_m[1]:<12.4f} {avg_theme_m[2]:<21.4f} {avg_b_theme_m[0]:<12.4f} {avg_b_theme_m[1]:<12.4f} {avg_b_theme_m[2]:<12.4f}\")\n",
    "print()\n",
    "\n",
    "print(\"Phrase-Level Material Boundary\")\n",
    "print(f\"{'Method 1':<60} {'Baseline'}\")\n",
    "print(f\"{'Window':<12} {'Precision':<12} {'Recall':<12} {'F1':<21} {'Window':<12}\")\n",
    "print(f\"{'.5':<12} {avg_phrase_p5[0]:<12.4f} {avg_phrase_p5[1]:<12.4f} {avg_phrase_p5[2]:<21.4f} {avg_b_phrase_p5 [0]:<12.4f} {avg_b_phrase_p5 [1]:<12.4f} {avg_b_phrase_p5 [2]:<12.4f}\")\n",
    "print(f\"{'3':<12} {avg_phrase_3[0]:<12.4f} {avg_phrase_3[1]:<12.4f} {avg_phrase_3[2]:<21.4f} {avg_b_phrase_3[0]:<12.4f} {avg_b_phrase_3[1]:<12.4f} {avg_b_phrase_3[2]:<12.4f}\")\n",
    "print(f\"{'measure':<12} {avg_phrase_m[0]:<12.4f} {avg_phrase_m[1]:<12.4f} {avg_phrase_m[2]:<21.4f} {avg_b_phrase_m[0]:<12.4f} {avg_b_phrase_m[1]:<12.4f} {avg_b_phrase_m[2]:<12.4f}\")\n",
    "\n",
    "\n",
    "# print(\"Phrase-Level Material Boundary\")\n",
    "# print('Baseline')\n",
    "# print(f\"{'Window':<12} {'Precision':<12} {'Recall':<12} {'F1':<12}\")\n",
    "# print(f\"{'.5':<12} {avg_b_phrase_p5[0]:<12.4f} {avg_b_phrase_p5[1]:<12.4f} {avg_b_phrase_p5[2]:<12.4f}\")\n",
    "# print(f\"{'3':<12} {avg_b_phrase_3[0]:<12.4f} {avg_b_phrase_3[1]:<12.4f} {avg_b_phrase_3[2]:<12.4f}\")\n",
    "# print(f\"{'measure':<12} {avg_b_phrase_m[0]:<12.4f} {avg_b_phrase_m[1]:<12.4f} {avg_b_phrase_m[2]:<12.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23514d6-b62c-4bf5-8957-d7e681318b89",
   "metadata": {},
   "source": [
    "## Eval\n",
    "250211 ver ('struct_mark_prev')\n",
    "1. Section Boundary \n",
    "|  | Proposed Method |  |  | Baseline |  |  |\n",
    "|:---:|:---:|:---:|:---:|:---:|:---:|:---:|\n",
    "| window | Precision | Recall | F1 | Precision | Recall | F1 |\n",
    "| 0.5 s | 0.8714 | 0.7289 | 0.7763 | 0.6072 | 0.1500 | 0.2349 |\n",
    "| 3 s | 0.9327 | 0.7887 | 0.8368 | 0.8878 | 0.2181 | 0.3421 |\n",
    "| 1 measure | 0.9117 | 0.7682 | 0.8161 | 0.8276 | 0.2003 | 0.3150 |\n",
    "\n",
    "\n",
    "2. Thematic Material Boundary\n",
    "| Method 1 | Baseline |  |  | Baseline |  |  |\n",
    "|:---:|:---:|:---:|:---:|:---:|:---:|:---:|\n",
    "| Window | Precision | Recall | F1 | Window | Recall | F1 |\n",
    "| .5 | 0.3398 | 0.5019 | 0.3863 | 0.3343 | 0.3092 | 0.2987 |\n",
    "| 3 | 0.5131 | 0.8155 | 0.6050 | 0.7043 | 0.6745 | 0.6479 |\n",
    "| measure | 0.4486 | 0.6819 | 0.5189 | 0.5977 | 0.5426 | 0.5319 |\n",
    "\n",
    "3. Phrase-Level Material Boundary\n",
    "|  | Baseline |  |  |\n",
    "|:---:|:---:|:---:|---|\n",
    "| Window | Precision | Recall | F1 |\n",
    "| .5 | 0.3191 | 0.5190 | 0.3917 |\n",
    "| 3 | 0.5715 | 0.9328 | 0.7025 |\n",
    "| measure | 0.5050 | 0.8227 | 0.6204 |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
